{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79dd13-71d8-4967-ac2a-1658d1502786",
   "metadata": {},
   "outputs": [],
   "source": [
    "Consider following code to answer further questions:\n",
    "import pandas as pd\n",
    "course_name = [‘Data Science’, ‘Machine Learning’, ‘Big Data’, ‘Data Engineer’]\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {‘course_name’ : course_name, ‘duration’ : duration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eacc3b-c2bb-4edc-9dbf-cc6bf2ec1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371fdfaf-3850-4a55-87c3-a0e29c23d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "To print the data present in the second row of the DataFrame df, you can use the iloc indexer with the row number 1 (since indexing is zero-based in Python). Here's the code to print the data in the second row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc9e44-1f5e-41f1-9af4-670433926055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data in the second row (index 1)\n",
    "second_row_data = df.iloc[1]\n",
    "print(second_row_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d2b9d-4776-4af1-8647-5a963e3e6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_name    Machine Learning\n",
    "duration                      3\n",
    "Name: 1, dtype: object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc634de-7b55-4592-b711-70c8af78c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619cb66-2dc3-4088-804b-6da148d1dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "In Pandas, both loc and iloc are used for indexing and selecting data from a DataFrame, but they have different ways of specifying the location of data:\n",
    "\n",
    "loc:\n",
    "\n",
    "loc is primarily label-based indexing, which means it uses row and column labels to select data.\n",
    "You can use meaningful row and column labels (such as column names or custom row indices) to access data.\n",
    "It includes the endpoint when slicing (e.g., df.loc[0:2] includes rows 0, 1, and 2).\n",
    "You can also use boolean arrays to filter rows based on conditions.\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e34756-cbc6-4570-a2f5-558625730ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1, 'course_name']  # Selects the value at row 1 and column 'course_name'\n",
    "df.loc[0:2]               # Selects rows 0, 1, and 2\n",
    "df.loc[df['duration'] > 3]  # Selects rows where 'duration' is greater than 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0922ea7-8c6a-4d34-a5cd-579dfdf1249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iloc:\n",
    "\n",
    "iloc is primarily integer-based indexing, which means it uses integer positions to select data.\n",
    "You can use integer row and column indices to access data.\n",
    "It does not include the endpoint when slicing (e.g., df.iloc[0:2] includes rows 0 and 1, but not 2).\n",
    "You can also use integer arrays or lists to select specific rows or columns based on their positions.\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675de52-0a50-40ed-b415-b27ae716f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1, 0]     # Selects the value at row 1 and column 0 (position-based)\n",
    "df.iloc[0:2]      # Selects rows 0 and 1\n",
    "df.iloc[[0, 2]]   # Selects rows 0 and 2\n",
    "df.iloc[:, 1]     # Selects all rows of column 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54058638-a142-47d2-b759-63d1415bd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "In summary, the key difference between loc and iloc is in how they index and select data:\n",
    "\n",
    "loc uses label-based indexing and includes the endpoint when slicing.\n",
    "iloc uses integer-based indexing and excludes the endpoint when slicing.\n",
    "You can choose the appropriate indexer based on your specific data selection needs and whether you prefer to use labels or integer positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db68bb-c761-42ee-b257-06046cbdfc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7604024-a008-4abd-94db-441759d11b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "To reindex the given DataFrame using the variable reindex = [3, 0, 1, 2] and store it in the variable new_df, you can use the reindex() method. After reindexing, you can use new_df.loc[2] and new_df.iloc[2] to access data. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e94fb5-f6b7-45d5-9f07-61a71c64c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loc:\n",
      "course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Using iloc:\n",
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "# Reindex the DataFrame using the 'reindex' variable\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex)\n",
    "\n",
    "# Access data using loc and iloc\n",
    "data_loc = new_df.loc[2]\n",
    "data_iloc = new_df.iloc[2]\n",
    "\n",
    "print(\"Using loc:\")\n",
    "print(data_loc)\n",
    "print(\"\\nUsing iloc:\")\n",
    "print(data_iloc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5486472-0f8d-4dac-b7b9-d03aa782ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "We first create the original DataFrame df with two columns: 'course_name' and 'duration'.\n",
    "\n",
    "We define the reindex variable as [3, 0, 1, 2], which specifies the new order of rows.\n",
    "\n",
    "We use the reindex() method on the original DataFrame df to reindex it based on the order specified in reindex. The result is stored in the variable new_df.\n",
    "\n",
    "We access data at index 2 using both new_df.loc[2] and new_df.iloc[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b8dd4-78f7-48e9-959b-5c49031cd6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's what the output means:\n",
    "\n",
    "new_df.loc[2] returns the row at the label/index 2, which corresponds to the row with label 1 in the original DataFrame. It returns the data for 'Big Data' with a duration of 6.\n",
    "\n",
    "new_df.iloc[2] returns the row at the integer position 2, which also corresponds to the row with label 1 in the original DataFrame. It returns the data for 'Machine Learning' with a duration of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a0c34-748f-46d0-b5f6-6a215276ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes, there is a difference in the outputs of new_df.loc[2] and new_df.iloc[2]. Let's explain the difference:\n",
    "\n",
    "new_df.loc[2]:\n",
    "\n",
    "It uses label-based indexing, so it looks for the row with the label/index 2.\n",
    "In the original DataFrame, the label 2 corresponds to the row with label 1.\n",
    "Therefore, new_df.loc[2] returns the data for the row with label 1.\n",
    "new_df.iloc[2]:\n",
    "\n",
    "It uses integer-based indexing, so it looks for the row at the integer position 2.\n",
    "In the original DataFrame, the row at position 2 corresponds to the row with label 1.\n",
    "Therefore, new_df.iloc[2] returns the data for the row at position 2, which is the same as the row with label 1.\n",
    "In summary, both new_df.loc[2] and new_df.iloc[2] are accessing the same row of data in this case because the label and integer position coincide for that row.\n",
    "\n",
    "Now, let's consider the code snippet you provided to create a DataFrame df1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769542ac-6504-43c7-9c05-66c9cceb40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame:\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4dc07-2aaa-44ea-8a83-bdb3dafc964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc5c8d-4d57-43a6-a953-7d4398b243a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can use Pandas to calculate the mean of each column in the DataFrame df1 and the standard deviation of the 'column_2'. Here's the code to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0d2806-cd24-4ced-948f-3d606797f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.594231\n",
      "column_2    0.481343\n",
      "column_3    0.557283\n",
      "column_4    0.468899\n",
      "column_5    0.262451\n",
      "column_6    0.532459\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation of 'column_2':\n",
      "0.3406089961358402\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the DataFrame\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame with random values\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Calculate the mean of each column\n",
    "column_means = df1.mean()\n",
    "\n",
    "# Calculate the standard deviation of 'column_2'\n",
    "column_2_std = df1['column_2'].std()\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "print(\"\\nStandard Deviation of 'column_2':\")\n",
    "print(column_2_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142bfd1-e7d9-455a-9a3d-bdd55a0ae630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5d991a-d733-4fe7-b95d-c65207b879d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "df1.mean() calculates the mean of each column in the DataFrame df1 and stores it in the column_means variable. The resulting Series contains the means for each column.\n",
    "\n",
    "df1['column_2'].std() calculates the standard deviation of 'column_2' and stores it in the column_2_std variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42275764-74b0-4440-813a-1872caf35861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b66373-ad7e-456b-a66b-61e166865c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938c6d8-ff8b-4b1f-b10b-416e57ab3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can replace the data present in the second row of 'column_2' with a string variable using df1.loc[] as suggested. However, you will encounter an error when trying to calculate the mean of 'column_2' because the column contains mixed data types (numeric values and strings), and Pandas cannot calculate the mean of mixed data types.\n",
    "\n",
    "Here's how you can replace the data and the subsequent error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ac5885a-f5d8-44bf-b05f-daac8060c7fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with replaced data:\n",
      "   column_1     column_2  column_3  column_4  column_5  column_6\n",
      "1  0.863274     0.266911  0.182204  0.382885  0.380515  0.232104\n",
      "2  0.995590  String Data  0.964113  0.621428  0.165661  0.809134\n",
      "3  0.168610     0.192035  0.286745  0.153309  0.692981  0.672201\n",
      "4  0.209190     0.310743  0.109464  0.335310  0.584415  0.956138\n",
      "5  0.680452     0.512203  0.228744  0.539139  0.247556  0.007559\n",
      "6  0.548795     0.124497  0.267175  0.666485  0.052968  0.536678\n",
      "\n",
      "Error message when calculating the mean of 'column_2':\n",
      "unsupported operand type(s) for +: 'float' and 'str'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the DataFrame\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame with random values\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Replace the data in the second row of 'column_2' with a string\n",
    "df1.loc[2, 'column_2'] = 'String Data'\n",
    "\n",
    "# Attempt to calculate the mean of 'column_2'\n",
    "try:\n",
    "    column_2_mean = df1['column_2'].mean()\n",
    "except Exception as e:\n",
    "    column_2_mean = str(e)\n",
    "\n",
    "# Print the DataFrame and the result (error message)\n",
    "print(\"DataFrame with replaced data:\")\n",
    "print(df1)\n",
    "print(\"\\nError message when calculating the mean of 'column_2':\")\n",
    "print(column_2_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58884c-d355-4922-bd6e-9b6d7dd83803",
   "metadata": {},
   "outputs": [],
   "source": [
    "When you run this code, it will replace the data in the second row of 'column_2' with the string 'String Data'. However, when you attempt to calculate the mean of 'column_2', you will get an error message similar to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef38477-35e5-4b49-81f0-1cab53286d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error message when calculating the mean of 'column_2':\n",
    "Data type mismatch in column 2. Expected np.float64 or np.int64, got str.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b11ddb-e41f-467c-9d0c-d311a0c4e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "The error occurs because Pandas cannot calculate the mean of a column containing mixed data types, and 'column_2' now contains both numeric and string data. To calculate the mean, you would need to ensure that the column contains consistent numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149c606-76bd-495f-b129-8748a85fbaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4734a3-c795-4fd2-bd31-4ccbbfbfa3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In Pandas, the term \"window functions\" refers to a group of functions and operations that allow you to perform calculations on a specific \"window\" or subset of data within your DataFrame. These functions are commonly used for time series data and rolling computations.\n",
    "\n",
    "Window functions are powerful tools for analyzing data over specific intervals, such as moving averages, cumulative sums, and more. They enable you to calculate metrics and aggregations for a set of consecutive rows in your DataFrame. Here's what you need to understand about window functions in Pandas:\n",
    "\n",
    "Types of Window Functions in Pandas:\n",
    "\n",
    "Rolling Functions (Rolling Windows): Rolling functions allow you to calculate values over a rolling or moving window of data. This window moves row by row across your DataFrame, and calculations are performed for each window. Common rolling functions include:\n",
    "\n",
    "rolling.mean(): Calculates the rolling mean.\n",
    "rolling.sum(): Calculates the rolling sum.\n",
    "rolling.std(): Calculates the rolling standard deviation.\n",
    "rolling.min(): Calculates the rolling minimum.\n",
    "rolling.max(): Calculates the rolling maximum.\n",
    "rolling.apply(): Applies a custom function to the rolling window.\n",
    "Expanding Functions (Expanding Windows): Expanding functions compute statistics for an expanding window of data. The window starts from the beginning of the DataFrame and grows as it moves through the data. Common expanding functions include:\n",
    "\n",
    "expanding.mean(): Calculates the expanding mean.\n",
    "expanding.sum(): Calculates the expanding sum.\n",
    "expanding.std(): Calculates the expanding standard deviation.\n",
    "expanding.min(): Calculates the expanding minimum.\n",
    "expanding.max(): Calculates the expanding maximum.\n",
    "Exponentially Weighted Moving Average (EWMA): EWMA is a type of rolling window calculation that gives more weight to recent data points. It's useful for smoothing time series data. The primary function for EWMA in Pandas is ewm().\n",
    "\n",
    "Aggregations with groupby(): While not strictly window functions, you can use the groupby() function in combination with aggregation functions like mean(), sum(), std(), etc., to perform calculations on grouped data within specified windows. This is useful for analyzing data by groups or categories.\n",
    "\n",
    "Here's a simplified example of using a rolling mean window function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd0ca59-7ff6-4e13-9283-8d9bf48d0d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    1.5\n",
      "2    2.5\n",
      "3    3.5\n",
      "4    4.5\n",
      "Name: values, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'values': [1, 2, 3, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the rolling mean with a window size of 2\n",
    "rolling_mean = df['values'].rolling(window=2).mean()\n",
    "\n",
    "print(rolling_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64bee5-5530-4c0c-906f-2e5fe0086bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this example, we calculate the rolling mean for the 'values' column with a window size of 2. The rolling mean is calculated for each window of two consecutive rows.\n",
    "\n",
    "These window functions are powerful for time series analysis, trend identification, and data smoothing tasks. They help you gain insights into your data by focusing on specific intervals or patterns within your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ee237-2cb5-4f02-bc7e-884f6d3cc7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "[Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d9782-972b-40e9-80b7-ea0532258de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "To print the current month and year using the pandas.datetime function, you can use Python's datetime module along with Pandas. Here's the code to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6556eb43-9100-4aab-ac6b-f71def5a47aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month: 9\n",
      "Current Year: 2023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_date_time = datetime.now()\n",
    "\n",
    "# Extract the current month and year from the datetime object\n",
    "current_month = current_date_time.month\n",
    "current_year = current_date_time.year\n",
    "\n",
    "# Print the current month and year\n",
    "print(\"Current Month:\", current_month)\n",
    "print(\"Current Year:\", current_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe813e-c01e-4c12-bba3-217d9a98805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "We import Pandas as pd and the datetime module to work with dates and times.\n",
    "\n",
    "We use datetime.now() to get the current date and time.\n",
    "\n",
    "We extract the current month and year from the current_date_time object using the .month and .year attributes, respectively.\n",
    "\n",
    "Finally, we print the current month and year.\n",
    "\n",
    "When you run this code, it will print the current month and year based on the date and time when the code is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af85a9-b622-4739-88ba-23b832ae5389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5c1b2-eb3f-4f8f-a32c-1914375d48b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45206a7-9ef9-472d-bb9e-e36d959e71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can create a Python program that takes two dates as input in the format 'YYYY-MM-DD', calculates the difference between them in days, hours, and minutes using Pandas' timedelta, and then displays the result. Here's a sample program to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e146fa0-b3ca-4ebe-b678-ddaa807defad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the start date (YYYY-MM-DD):  1998-07-15\n",
      "Enter the end date (YYYY-MM-DD):  2023-09-23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Difference:\n",
      "Days: 9201\n",
      "Hours: 0\n",
      "Minutes: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate the time difference\n",
    "def calculate_time_difference(start_date, end_date):\n",
    "    try:\n",
    "        # Convert input strings to datetime objects\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "\n",
    "        # Calculate the time difference\n",
    "        time_difference = end_date - start_date\n",
    "\n",
    "        # Extract days, hours, and minutes\n",
    "        days = time_difference.days\n",
    "        hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "        minutes, _ = divmod(remainder, 60)\n",
    "\n",
    "        return days, hours, minutes\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Input dates from the user\n",
    "start_date = input(\"Enter the start date (YYYY-MM-DD): \")\n",
    "end_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "\n",
    "# Calculate the time difference\n",
    "result = calculate_time_difference(start_date, end_date)\n",
    "\n",
    "if result is not None:\n",
    "    days, hours, minutes = result\n",
    "    print(f\"Time Difference:\")\n",
    "    print(f\"Days: {days}\")\n",
    "    print(f\"Hours: {hours}\")\n",
    "    print(f\"Minutes: {minutes}\")\n",
    "else:\n",
    "    print(\"Invalid date format. Please use YYYY-MM-DD format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464efed-46fa-438e-bace-e373446fcb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this program:\n",
    "\n",
    "We define a function calculate_time_difference that takes two date strings as input, converts them to datetime objects using pd.to_datetime, calculates the time difference, and then extracts the days, hours, and minutes from the timedelta.\n",
    "\n",
    "The user is prompted to enter the start and end dates in 'YYYY-MM-DD' format.\n",
    "\n",
    "We call the calculate_time_difference function to calculate the time difference and display the result if the input dates are valid.\n",
    "\n",
    "If the input dates are not in the correct format, the program will print an error message.\n",
    "\n",
    "Make sure to run this program in a Python environment with Pandas installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e05aed-d14a-4b8d-9eca-c571d5eaf7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ef46f-3e28-41a8-9dbd-fbb26a07c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "To create a Python program that reads a CSV file containing categorical data, converts a specified column to a categorical data type, and displays the sorted data, you can use the Pandas library. Here's a sample program to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9682d-0583-46e6-94c5-a9c65d6bcd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the CSV file path:  shiva\n",
      "Enter the column name to convert to categorical:  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to read CSV file, convert column to categorical, and display sorted data\n",
    "def process_categorical_data(file_path, column_name, category_order):\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Convert the specified column to a categorical data type with custom category order\n",
    "        df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "        # Sort the DataFrame by the specified column\n",
    "        sorted_df = df.sort_values(by=column_name)\n",
    "\n",
    "        # Display the sorted data\n",
    "        print(\"Sorted Data:\")\n",
    "        print(sorted_df)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "    except KeyError:\n",
    "        print(\"Column not found in the DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Input file path, column name, and category order from the user\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "category_order = input(\"Enter the custom category order (comma-separated): \").split(',')\n",
    "\n",
    "# Call the function to process and display the data\n",
    "process_categorical_data(file_path, column_name, category_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865d0a3-8a63-4449-af02-6908b57c4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817eb7d9-92ee-4235-9956-58304753013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "To create a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time, you can use libraries like Pandas for data manipulation and Matplotlib for data visualization. Here's a sample program to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504c5b49-b916-485a-9e37-c5e0ae8f015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the CSV file path containing sales data:  555-555-5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to read CSV file, process data, and create a stacked bar chart\n",
    "def visualize_sales_data(file_path):\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Pivot the data to create a DataFrame suitable for a stacked bar chart\n",
    "        pivot_df = df.pivot(index='Date', columns='ProductCategory', values='Sales')\n",
    "\n",
    "        # Plot a stacked bar chart\n",
    "        pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Sales')\n",
    "        plt.title('Stacked Bar Chart of Sales by Product Category')\n",
    "        \n",
    "        # Show the chart\n",
    "        plt.legend(title='Product Category', loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "    except KeyError:\n",
    "        print(\"Required columns not found in the DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Input file path from the user\n",
    "file_path = input(\"Enter the CSV file path containing sales data: \")\n",
    "\n",
    "# Call the function to visualize the sales data\n",
    "visualize_sales_data(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3025ea-94a6-4633-a37f-8f2b5ef15487",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this program:\n",
    "\n",
    "We define a function visualize_sales_data that takes the file path as input. Inside the function, we:\n",
    "\n",
    "Read the CSV file into a DataFrame using pd.read_csv.\n",
    "Pivot the data to create a DataFrame suitable for a stacked bar chart using pivot.\n",
    "Plot a stacked bar chart using plot from Matplotlib.\n",
    "Customize the chart with labels and a title.\n",
    "The user is prompted to enter the file path containing sales data.\n",
    "\n",
    "We call the visualize_sales_data function to read and visualize the data. The program handles potential errors such as file not found or missing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110343f1-36b2-46cc-ad6f-3e589d3fee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table.\n",
    "The program should do the followingM\n",
    "I Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    "I Read the CSV file into a Pandas DataFrameR\n",
    "I Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    "I Display the mean, median, and mode in a table.\n",
    "Assume the CSV file contains the following columnsM\n",
    "I Student ID: The ID of the studentR\n",
    "I Test Score: The score of the student's test.\n",
    "Example usage of the program:\n",
    "Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "+-----------+--------+\n",
    "| Statistic | Value |\n",
    "+-----------+--------+\n",
    "| Mean | 79.6 |\n",
    "| Median | 82 |\n",
    "| Mode | 85, 90 |\n",
    "+-----------+--------+\n",
    "Assume that the CSV file student_data.csv contains the following data:\n",
    "Student ID,Test Score\n",
    "1,85\n",
    "2,90\n",
    "3,80\n",
    "4,75\n",
    "5,85\n",
    "6,82\n",
    "7,78\n",
    "8,85\n",
    "9,90\n",
    "10,85\n",
    "The program should calculate the mean, median, and mode of the test scores and display the results\n",
    "in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37efa88-c224-4523-9c1b-51969a1552e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Function to calculate mean, median, and mode of test scores\n",
    "def calculate_statistics(file_path):\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Calculate mean, median, and mode\n",
    "        mean_score = df['Test Score'].mean()\n",
    "        median_score = df['Test Score'].median()\n",
    "        mode_scores = df['Test Score'].mode()\n",
    "\n",
    "        # Create a table to display the results\n",
    "        table = [\n",
    "            ['Statistic', 'Value'],\n",
    "            ['Mean', mean_score],\n",
    "            ['Median', median_score],\n",
    "            ['Mode', ', '.join(map(str, mode_scores))]\n",
    "        ]\n",
    "\n",
    "        # Display the results using tabulate\n",
    "        result_table = tabulate(table, headers='firstrow', tablefmt='fancy_grid')\n",
    "        print(result_table)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "    except KeyError:\n",
    "        print(\"Required columns not found in the DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Input file path from the user\n",
    "file_path = input(\"Enter the file path of the CSV file containing student data: \")\n",
    "\n",
    "# Call the function to calculate and display statistics\n",
    "calculate_statistics(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf7d81-7587-4a83-9071-1d0f7db95a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this program:\n",
    "\n",
    "We define a function calculate_statistics that takes the file path as input. Inside the function, we:\n",
    "\n",
    "Read the CSV file into a DataFrame using pd.read_csv.\n",
    "Calculate the mean, median, and mode of the 'Test Score' column.\n",
    "Create a table to display the results using the tabulate library.\n",
    "Display the results using tabulate's tabulate function with a 'fancy_grid' table format.\n",
    "The user is prompted to enter the file path containing student data.\n",
    "\n",
    "We call the calculate_statistics function to calculate and display the statistics. The program handles potential errors such as file not found or missing columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
